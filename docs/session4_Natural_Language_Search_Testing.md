# Session 4: Natural Language Search Testing

**Date:** November 9, 2025
**Focus:** Exploring and testing the AI search API with natural language queries

## Overview

After completing the refactoring to InvenioRDM's resource pattern in Session 3, this session focused on testing the natural language capabilities of the AI search interface. The system uses sentence transformers (all-MiniLM-L6-v2) to understand semantic meaning, allowing users to search with conversational queries rather than just keywords.

## Natural Language Query Examples

### Query 1: Finding Spooky Books

**User intent:** Find Dracula and other horror/gothic literature

**Query:**
```bash
curl -k "https://127.0.0.1:5000/api/aisearch/search?q=spooky%20horror%20vampire%20gothic&limit=5&summaries=true"
```

**Results:**
```json
{
  "query": "spooky horror vampire gothic",
  "results": [
    {
      "title": "Dracula",
      "semantic_score": 0.527,
      "summary": "A classic work titled 'Dracula' was written by Bram Stoker..."
    },
    {
      "title": "Carmilla",
      "semantic_score": 0.280,
      "summary": "A classic work titled 'Carmilla' was written in the early 1800s..."
    },
    {
      "title": "Grimms' Fairy Tales",
      "semantic_score": 0.267
    },
    {
      "title": "The Legend of Sleepy Hollow",
      "semantic_score": 0.256
    },
    {
      "title": "Frankenstein; Or, The Modern Prometheus",
      "semantic_score": 0.246
    }
  ]
}
```

**Analysis:**
- Successfully found Dracula with highest semantic score (0.527)
- Retrieved thematically related gothic/horror classics
- Carmilla (vampire story predating Dracula) ranked second
- AI summaries provide context for each result

### Query 2: Finding Similar Books to Dracula

**Using the similarity endpoint to find books with similar embeddings:**

```bash
curl -k "https://127.0.0.1:5000/api/aisearch/similar/4csds-ga345?limit=5"
```

**Results:**
```json
{
  "record_id": "4csds-ga345",
  "similar": [
    {
      "title": "Heart of Darkness",
      "similarity": 0.483
    },
    {
      "title": "Frankenstein; Or, The Modern Prometheus",
      "similarity": 0.481
    }
  ],
  "total": 91
}
```

**Analysis:**
- Vector similarity based on embedding space
- Heart of Darkness (dark exploration themes) most similar
- Frankenstein (gothic horror) very close match
- Total of 91 books with measurable similarity

### Query 3: Conversational Search - "Find Me Scary Stories"

**Testing natural language understanding:**

```bash
curl -k "https://127.0.0.1:5000/api/aisearch/search?q=find%20me%20scary%20stories&limit=5&summaries=true"
```

**Parsed Query:**
```json
{
  "original_query": "find me scary stories",
  "intent": "search",
  "semantic_query": "scary stories"
}
```

**Results:**
```json
{
  "results": [
    {
      "title": "Dracula",
      "semantic_score": 0.364
    },
    {
      "title": "The Legend of Sleepy Hollow",
      "semantic_score": 0.319
    },
    {
      "title": "Grimms' Fairy Tales",
      "semantic_score": 0.258
    },
    {
      "title": "Rip Van Winkle",
      "semantic_score": 0.250
    },
    {
      "title": "Carmilla",
      "semantic_score": 0.243
    }
  ]
}
```

**Analysis:**
- QueryParser successfully cleaned conversational language
- Extracted semantic meaning: "find me" ‚Üí removed, "scary stories" ‚Üí preserved
- Results appropriately match horror/spooky theme
- Natural language understood without requiring exact keywords

### Query 4: Intent-Based Search - "I Want to Read Something Romantic"

**Testing longer conversational query:**

```bash
curl -k "https://127.0.0.1:5000/api/aisearch/search?q=I%20want%20to%20read%20something%20romantic&limit=3"
```

**Results:**
```json
{
  "results": [
    {
      "title": "The Romance of Lust: A classic Victorian erotic novel"
    },
    {
      "title": "The Enchanted April"
    },
    {
      "title": "Don't Marry; or, Advice on How, When and Who to Marry"
    }
  ]
}
```

**Analysis:**
- Understood user intent from conversational phrasing
- "I want to read" ‚Üí removed as filler
- "romantic" ‚Üí semantically matched to romance genre
- Retrieved appropriate romance-themed works

### Query 5: Question-Style Query - "What Books Are About Exploring Nature"

**Testing question format:**

```bash
curl -k "https://127.0.0.1:5000/api/aisearch/search?q=what%20books%20are%20about%20exploring%20nature&limit=3"
```

**Results:**
```json
{
  "results": [
    {
      "title": "Frankenstein; Or, The Modern Prometheus",
      "semantic_score": 0.363
    }
  ]
}
```

**Analysis:**
- Question format ("what books are about...") successfully parsed
- Semantic understanding of "exploring nature" theme
- Frankenstein matched (explores themes of nature and science)

## Natural Language Capabilities Demonstrated

### ‚úÖ Conversational Patterns Understood

The AI search successfully handles:

1. **Command-style queries:**
   - "find me scary stories"
   - "show me adventure tales"

2. **Intent-based queries:**
   - "I want to read something romantic"
   - "I'm looking for spooky books"

3. **Question-style queries:**
   - "what books are about..."
   - "which stories involve..."

4. **Keyword combinations:**
   - "spooky horror vampire gothic"
   - Direct semantic matching

### üîß Query Processing Pipeline

**How it works:**

1. **QueryParser** cleans conversational language:
   ```
   "find me scary stories" ‚Üí "scary stories"
   "I want to read something romantic" ‚Üí "romantic"
   "what books are about exploring nature" ‚Üí "exploring nature"
   ```

2. **Sentence Transformer** creates semantic embeddings:
   - Model: `all-MiniLM-L6-v2`
   - Converts text to 384-dimensional vectors
   - Captures semantic meaning, not just keywords

3. **Similarity Search** finds matches:
   - Cosine similarity between query embedding and book embeddings
   - Hybrid scoring combines semantic + metadata matches
   - Returns ranked results

4. **Result Objects** structure response:
   - `SearchResult` with parsed query, results, scores
   - Optional AI-generated summaries
   - Total count and pagination support

## API Endpoints Tested

### 1. Natural Language Search
**Endpoint:** `GET /api/aisearch/search`

**Parameters:**
- `q` or `query` - Natural language query string
- `limit` - Maximum results (default: 10)
- `summaries` - Include AI summaries (true/false)
- `semantic_weight` - Weight for semantic similarity (0-1)
- `metadata_weight` - Weight for metadata matching (0-1)

**Example:**
```bash
curl -k "https://127.0.0.1:5000/api/aisearch/search?q=find%20me%20scary%20stories&limit=5&summaries=true"
```

### 2. Similar Records Search
**Endpoint:** `GET /api/aisearch/similar/{record_id}`

**Parameters:**
- `record_id` - InvenioRDM record ID (URL path)
- `limit` - Maximum similar records (default: 10)

**Example:**
```bash
curl -k "https://127.0.0.1:5000/api/aisearch/similar/4csds-ga345?limit=5"
```

### 3. Service Status
**Endpoint:** `GET /api/aisearch/status`

**Returns:**
```json
{
  "status": "ready",
  "embeddings_loaded": true,
  "embeddings_count": 92,
  "embeddings_file": "/path/to/embeddings.json"
}
```

## Semantic Understanding Examples

### Theme Understanding

The system understands thematic concepts:

- **"Scary"** ‚Üí Gothic horror, vampires, dark fairy tales
- **"Romantic"** ‚Üí Romance novels, love stories
- **"Adventure"** ‚Üí Exploration, journeys, quests
- **"Nature"** ‚Üí Natural world, scientific exploration

### Context Awareness

The embeddings capture contextual relationships:

- **Dracula** ‚Üî **Carmilla** (both vampire stories)
- **Dracula** ‚Üî **Frankenstein** (both gothic horror)
- **Dracula** ‚Üî **Heart of Darkness** (both dark, atmospheric)

### Synonym Recognition

Natural language understanding handles variations:

- "scary" = "spooky" = "horror" = "frightening"
- "romantic" = "romance" = "love stories"
- "find" = "show" = "search for"

## Technical Observations

### Performance

- **Query processing:** ~1-2 seconds for search
- **Similarity matching:** <1 second
- **AI summary generation:** 5-9 seconds (when enabled)
- **Embeddings loaded:** 92 books in memory

### Hybrid Scoring Formula

```
hybrid_score = (semantic_weight √ó semantic_score) + (metadata_weight √ó metadata_score)
```

**Default weights:**
- Semantic: 0.7
- Metadata: 0.3

**Example scoring:**
```json
{
  "title": "Dracula",
  "semantic_score": 0.527,
  "metadata_score": 0.0,
  "hybrid_score": 0.369  // (0.7 √ó 0.527) + (0.3 √ó 0.0)
}
```

### Query Intent Detection

The system currently supports:
- **Search intent** - All queries default to search
- Future expansion could add:
  - Recommendation intent
  - Filter intent
  - Browse intent

## User Experience Insights

### What Works Well

‚úÖ **Natural phrasing accepted**
- Users don't need to learn special syntax
- Conversational queries work immediately
- Question formats understood

‚úÖ **Semantic matching superior to keywords**
- "Scary stories" finds horror books without exact keyword match
- Theme-based searching more intuitive
- Synonyms handled automatically

‚úÖ **Similarity search enables discovery**
- "If you liked Dracula, try these..."
- Vector embeddings capture thematic relationships
- Recommendation-style browsing

### Areas for Enhancement

**Potential improvements identified:**

1. **Query expansion**
   - Expand "romantic" ‚Üí "romance", "love", "relationship"
   - Use WordNet or knowledge graphs

2. **Faceted filters**
   - Combine natural language with structured filters
   - "scary stories from the 1800s"
   - "romantic novels with female protagonists"

3. **Multi-intent queries**
   - "find scary stories but not too violent"
   - Handle negation and qualification

4. **Personalization**
   - Learn from user's past searches
   - Adjust semantic weights based on feedback

## Comparison: Natural Language vs Keywords

### Keyword Search Limitations
```
Query: "vampire"
Results: Only books with "vampire" in title/description
Misses: Books about vampires without using the word
```

### Natural Language Advantages
```
Query: "spooky horror vampire gothic"
Results: Dracula, Carmilla, Frankenstein, Gothic tales
Includes: Thematically related books based on embeddings
```

## Conclusion

The natural language search interface successfully demonstrates:

1. **Conversational query understanding** - Users can ask questions naturally
2. **Semantic search capabilities** - Meaning-based matching, not just keywords
3. **Theme and context awareness** - Related works discovered through embeddings
4. **Flexible query formats** - Commands, questions, and statements all work
5. **InvenioRDM integration** - Properly follows resource/service pattern

The refactored module (from Session 3) provides a solid foundation for natural language search in InvenioRDM, making academic repository search more intuitive and discovery-oriented.

## Summary Quality Improvements

### Issue: Repetitive AI Summaries

During testing, the AI-generated summaries showed alarming repetition and factual inaccuracies:

**Example problematic summaries:**
```json
{
  "title": "Dracula",
  "summary": "A classic work titled 'Dracula' was written by Bram Stoker in the 1930s..."
}
```

**Problems identified:**
- Generic phrases: "is considered one of the greatest works"
- Factual errors: Dracula published 1897, not 1930s
- Repetitive structure across all results
- Limited information value

### Root Cause

Located in `ai_search_service.py:158`:

```python
# OLD CODE (placeholder)
summary_text = f"A classic work titled '{result['title']}'"
summary = self.model_manager.generate_summary(summary_text, ...)
```

The placeholder code was only feeding the **title** to the AI model, causing it to hallucinate details from minimal context.

### Solution: Use Real Metadata

Implemented proper metadata fetching using InvenioRDM's internal service layer:

**New implementation:**

1. **Added metadata fetching method** (`ai_search_service.py:74-93`):
```python
def _fetch_record_metadata(self, identity, record_id: str) -> Optional[dict]:
    """Fetch full record metadata from InvenioRDM."""
    try:
        # Use InvenioRDM's records service (not HTTP requests)
        record = current_rdm_records_service.read(identity, record_id)
        return record.data.get('metadata', {})
    except Exception as e:
        current_app.logger.warning(f"Error fetching metadata for {record_id}: {e}")
        return None
```

2. **Intelligent summary generation** (`ai_search_service.py:175-210`):
```python
# Fetch full record metadata
metadata = self._fetch_record_metadata(identity, result['record_id'])

if metadata and metadata.get('description'):
    description = metadata['description']

    # Summarize long descriptions (>500 chars)
    if len(description) > 500:
        summary = self.model_manager.generate_summary(
            description,
            max_length=150,  # Updated from 50
            min_length=50    # Updated from 10
        )
        result['summary'] = summary
    else:
        # Use description as-is if already concise
        result['summary'] = description
else:
    # Fallback: title + subjects
    subjects = metadata.get('subjects', []) if metadata else []
    subject_terms = ', '.join([s.get('subject', '') for s in subjects[:3]])
    if subject_terms:
        result['summary'] = f"{result['title']}. Subjects: {subject_terms}"
    else:
        result['summary'] = result['title']
```

3. **Updated summary length configuration** (`services/config.py:24-25`):
```python
summary_max_length = 150  # Increased from 50
summary_min_length = 50   # Increased from 10
```

### Results: Improved Summaries

**Before:**
```
"A classic work titled 'Dracula' was written by Bram Stoker in the 1930s..."
```

**After:**
```
"Dracula" by Bram Stoker is a Gothic horror novel written in the late 19th century.
The story unfolds through a series of letters, journal entries, and newspaper clippings.
The novel delves into themes of fear, seduction, and the supernatural.
```

**Improvements:**
- ‚úÖ Factually accurate (uses actual book descriptions)
- ‚úÖ Complete sentences (no mid-sentence truncation)
- ‚úÖ Meaningful context about plot and themes
- ‚úÖ Unique summaries for each book

### Key Technical Decision

**Used InvenioRDM service layer instead of HTTP requests:**

‚ùå **Wrong approach:**
```python
import requests
response = requests.get(f"{api_url}/records/{record_id}")
```

‚úÖ **Correct approach:**
```python
from invenio_rdm_records.proxies import current_rdm_records_service
record = current_rdm_records_service.read(identity, record_id)
```

**Rationale:** We're inside InvenioRDM - use internal business logic APIs rather than external HTTP endpoints for better performance and proper integration.

---

## Invenio Jobs and CLI Integration

Following the pattern from `invenio-notify`, integrated the embeddings generator with InvenioRDM's job management system.

### Implementation

**1. Created Job Definition** (`invenio_aisearch/jobs.py`):
```python
from invenio_jobs.jobs import JobType
from invenio_aisearch import tasks

class RegenerateEmbeddingsJob(JobType):
    """Job for regenerating embeddings for all records."""

    task = tasks.regenerate_all_embeddings
    id = 'regenerate_embeddings'
    title = 'Regenerate AI Search Embeddings'
    description = 'Generate embeddings for all InvenioRDM records for semantic search'
```

**2. Added Entry Point** (`pyproject.toml:58-59`):
```toml
[project.entry-points."invenio_jobs.jobs"]
regenerate_embeddings = "invenio_aisearch.jobs:RegenerateEmbeddingsJob"
```

**3. Enhanced CLI Commands** (`invenio_aisearch/cli.py`):

Fixed CLI to use extension-registered service instead of undefined functions:

```python
# Get service from extension
service = current_app.extensions["invenio-aisearch"].search_service

# Use system identity for CLI operations
from invenio_access.permissions import system_identity
result_obj = service.search(identity=system_identity, query=query, limit=limit)
```

### Available CLI Commands

**Generate Embeddings:**
```bash
# Synchronous (blocking)
invenio aisearch generate-embeddings

# Asynchronous (background Celery task)
invenio aisearch generate-embeddings --async
```

**Check Service Status:**
```bash
invenio aisearch status
```

**Test Queries:**
```bash
invenio aisearch test-query "your natural language query"
invenio aisearch test-query "scary stories" --limit 3
```

### Testing the CLI Integration

#### Test 1: Generate Embeddings

```bash
$ pipenv run invenio aisearch generate-embeddings
```

**Output:**
```
Generating embeddings for all records...
This may take several minutes...
Loading embedding model (sentence-transformers/all-MiniLM-L6-v2)...
‚úì Embedding model loaded

============================================================
Embedding Generation Complete
============================================================
Total records: 92
Embeddings generated: 92
Errors: 0
File size: 0.95 MB
Saved to: /home/steve/code/cl/Invenio/v13-ai/embeddings.json
============================================================
```

**Results:**
- ‚úÖ 92 records processed
- ‚úÖ 0 errors
- ‚úÖ 0.95 MB embeddings file
- ‚úÖ All embeddings generated successfully

#### Test 2: Check Status

```bash
$ pipenv run invenio aisearch status
```

**Output:**
```
============================================================
AI Search Service Status
============================================================
Embeddings file: /home/steve/code/cl/Invenio/v13-ai/embeddings.json
Status: READY ‚úì
Embeddings loaded: 92

Available endpoints:
  Search: https://127.0.0.1:5000/api/aisearch/search?q=<query>
  Similar: https://127.0.0.1:5000/api/aisearch/similar/<record_id>
  Status: https://127.0.0.1:5000/api/aisearch/status

Configuration:
  Semantic weight: 0.7
  Metadata weight: 0.3
  Default limit: 10
============================================================
```

**Status:** Service ready with 92 embeddings loaded.

#### Test 3: CLI Query - "Stories About Adventure at Sea"

```bash
$ pipenv run invenio aisearch test-query "stories about adventure at sea" --limit 3
```

**Output:**
```
============================================================
Query: "stories about adventure at sea"
============================================================

Intent: search
Attributes: ['genre_adventure']
Search terms: ['adventure']

Results (3):

1. The Adventures of Tom Sawyer, Complete
   Semantic: 0.390 | Metadata: 1.000 | Hybrid: 0.573

2. Adventures of Huckleberry Finn
   Semantic: 0.377 | Metadata: 1.000 | Hybrid: 0.564

3. The Adventures of Ferdinand Count Fathom ‚Äî Complete
   Semantic: 0.336 | Metadata: 1.000 | Hybrid: 0.535
```

**Analysis:**
- Query parser extracted "adventure" search term
- Detected genre attribute: `genre_adventure`
- Metadata weight boosted titles containing "adventure"
- Hybrid scoring (70% semantic + 30% metadata) ranked results

#### Test 4: CLI Query - "Stories That Mostly Happen at Sea"

```bash
$ pipenv run invenio aisearch test-query "stories that are mostly happen at sea" --limit 5
```

**Output:**
```
============================================================
Query: "stories that are mostly happen at sea"
============================================================

Intent: search
Attributes: []
Search terms: []

Results (5):

1. Moby Dick; Or, The Whale
   Semantic: 0.377 | Metadata: 0.000 | Hybrid: 0.264

2. Moby Dick; Or, The Whale
   Semantic: 0.377 | Metadata: 0.000 | Hybrid: 0.264

3. Gulliver's Travels into Several Remote Nations of the World
   Semantic: 0.324 | Metadata: 0.000 | Hybrid: 0.227

4. Heart of Darkness
   Semantic: 0.319 | Metadata: 0.000 | Hybrid: 0.223

5. Treasure Island
   Semantic: 0.294 | Metadata: 0.000 | Hybrid: 0.206
```

**Analysis:**
- **Pure semantic matching** (no keyword extraction from conversational phrasing)
- Metadata score: 0.000 (no titles contain "sea")
- **Correctly identified maritime books** based on description embeddings:
  - Moby Dick (whaling voyage) ‚öì
  - Gulliver's Travels (sea captain adventures) üö¢
  - Heart of Darkness (river journey) üõ∂
  - Treasure Island (pirate adventure) üè¥‚Äç‚ò†Ô∏è

**Key Insight:** Demonstrates semantic search superiority over keyword matching. Even without "sea" in titles, the embeddings captured thematic content from book descriptions.

### Embeddings: Full-Text vs Metadata

**Current Implementation:**
Embeddings are generated from **metadata only**, not full book text:

**Text sources** (`generate_embeddings.py:76-104`):
1. Title
2. Description (summary from metadata)
3. Subjects (genre tags)
4. Additional descriptions

**Not included:**
- Full book text (`.txt` files attached to records)

**Code comment shows planned enhancement:**
```python
# For a full implementation, download the actual book file:
# files = record.get('files', {}).get('entries', {})
# for filename, file_info in files.items():
#     if filename.endswith('.txt'):
#         file_url = f"{api_url}/records/{record['id']}/files/{filename}/content"
#         # Download and extract text...
```

**Impact:** Semantic search matches against book descriptions and metadata, not full content. This is sufficient for title/theme/genre matching but wouldn't find specific passages or detailed plot elements within the full text.

---

## Integration Benefits

### Invenio Jobs Integration

**Admin UI Scheduling:**
- Job appears in Invenio Admin interface
- Can schedule recurring embedding regeneration
- Monitor job execution history
- Set up automated nightly rebuilds

**Celery Background Processing:**
```bash
invenio aisearch generate-embeddings --async
```
- Returns immediately with task ID
- Runs in background via Celery worker
- Doesn't block CLI or web server

### CLI Developer Experience

**Quick Commands:**
```bash
# Check if service is ready
invenio aisearch status

# Regenerate after adding new records
invenio aisearch generate-embeddings

# Test a query without HTTP requests
invenio aisearch test-query "romantic novels"
```

**Benefits:**
- No need to write test scripts
- Fast iteration during development
- Easy debugging of query parsing
- Visibility into semantic vs metadata scoring

### Consistent Architecture

Following `invenio-notify` pattern ensures:
- ‚úÖ Standard InvenioRDM integration points
- ‚úÖ Familiar patterns for other developers
- ‚úÖ Proper entry point registration
- ‚úÖ Extension-based service management
- ‚úÖ System identity for CLI operations

---

## Next Steps

Potential enhancements for future sessions:

- **Full-text embeddings** - Generate embeddings from complete book text, not just metadata
- **Advanced query parsing** - Handle complex queries with multiple constraints
- **Filter integration** - Combine natural language with faceted search
- **Relevance feedback** - Learn from user interactions
- **Multi-modal search** - Combine text with metadata filters
- **Query suggestions** - Autocomplete and query refinement
- **Search analytics** - Track popular queries and results
- **Incremental embedding updates** - Update embeddings when records change

---

**Session Summary:**
Session 4 accomplished natural language search testing, summary quality improvements, and Invenio jobs/CLI integration. The system successfully understands conversational queries, generates accurate summaries from real metadata, and provides developer-friendly CLI tools. Semantic search correctly identifies maritime books without keyword matching. Found Dracula! üßõ‚öì
